[{"content":"Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. DynamoDB lets you offload the administrative burdens of operating and scaling a distributed database so that you don\u0026rsquo;t have to worry about hardware provisioning, setup, and configuration, replication, software patching, or cluster scaling. DynamoDB also offers encryption at rest, which eliminates the operational burden and complexity involved in protecting sensitive data.\nThis cheat sheet will cover the most commonly used scenarios of data operations in DynamoDB with AWS DynamoDB Document client for JavaScript/Nodejs. The DynamoDB Document Client is the easiest and most preferred way to interact with a DynamoDB database from a Nodejs or JavaScript application.\nGETTING STARTED Install npm install aws-sdk\nConfigure const AWS = require(\u0026#39;aws-sdk\u0026#39;) const ddb = new AWS.DynamoDB.DocumentClient() CREATE ITEM Let\u0026rsquo;s create a new item for the new user. This user will have one album and one image in the album.\nasync function createItem (buildInfo) { console.log(\u0026#39;Creating new item\u0026#39;) let params = { TableName: tableName, Item: { \u0026#39;userId\u0026#39;: \u0026#39;johnDoe\u0026#39;, \u0026#39;createdAt\u0026#39;: 1598362623, \u0026#39;updatedAt\u0026#39;: 1598362623, \u0026#39;albums\u0026#39;: { \u0026#39;album1\u0026#39;: { \u0026#39;id\u0026#39;: \u0026#39;album-kjuijhs342\u0026#39;, \u0026#39;createdAt\u0026#39;: 1598362623, \u0026#39;updatedAt\u0026#39;: 1598362623, \u0026#39;description\u0026#39;: \u0026#39;My First Album\u0026#39;, \u0026#39;Title\u0026#39;: \u0026#39;Holidays\u0026#39;, \u0026#39;images\u0026#39;: { \u0026#39;img-1\u0026#39;: { \u0026#39;filename\u0026#39;: \u0026#39;johndoe/album1/e8TtkC5xyv4.jpg\u0026#39;, \u0026#39;s3Url\u0026#39;: \u0026#39;s3://photo-bucket/johndoe/album1/e8TtkC5xyv4.jpg\u0026#39;, \u0026#39;tags\u0026#39;: [\u0026#39;nature\u0026#39;, \u0026#39;animals\u0026#39;] } } } } } } try { await ddb.put(params).promise() } catch (error) { console.log(error) } } SCAN Scan and returns all items in a table\nasync function scan() { let params = { TableName: tableName } try { let x = await ddb.scan(params).promise() console.log(x) } catch (error) { console.error(error) } } GET ITEM Get a single item from the table\nasync function getItem() { var params = { TableName: tableName, Key: { \u0026#39;userId\u0026#39;: \u0026#39;johnDoe\u0026#39; } } try { let res = await ddb.get(params).promise() console.log(res) } catch (error) { console.error(error) } } GET ONLY SOME DATA FROM AN ITEM this will return only the tags from img1 and img2 in the result.\nasync function getSome() { var params = { TableName: tableName, ProjectionExpression: `albums.album1.images.#imageName1.tags, albums.album1.images.#imageName2.tags`, ExpressionAttributeNames: { \u0026#39;#imageName1\u0026#39;: \u0026#39;img-1\u0026#39;, \u0026#39;#imageName2\u0026#39;: \u0026#39;img-2\u0026#39; }, Key: { \u0026#39;userId\u0026#39;: \u0026#39;johnDoe\u0026#39;, } } try { let result = await ddb.get(params).promise() console.log(JSON.stringify(result)) } catch (error) { console.error(error) } } DELETE ITEM deletes a single item from the table\nasync function deleteItem () { let params = { TableName: tableName, Key: { userId: \u0026#39;johnDoe\u0026#39;, } } try { await ddb.delete(params).promise() } catch (error) { console.error(error) } } QUERY Query an item from a table\nasync function query () { let params = { TableName: tableName, KeyConditionExpression: \u0026#39;userId = :id \u0026#39;, ExpressionAttributeValues: { \u0026#39;:id\u0026#39;: \u0026#39;johnDoe\u0026#39; } } try { let result = await ddb.query(params).promise() console.log(result) } catch (error) { console.error(error) } } UPDATE A TOP-LEVEL ATTRIBUTE Let\u0026rsquo;s update the updatedAt key\nasync function updateItem () { const params = { TableName: tableName, Key: { userId: \u0026#39;johnDoe\u0026#39; }, UpdateExpression: \u0026#39;set updatedAt = :newUpdatedAt\u0026#39;, ExpressionAttributeValues: { \u0026#39;:newUpdatedAt\u0026#39;: 1598367687 }, ReturnValues: \u0026#39;UPDATED_NEW\u0026#39; } try { await ddb.update(params).promise() } catch (error) { console.error(error) } } UPDATE A NESTED ATTRIBUTE Here we will add a new attribute(size) to img-1 of album1\nasync function updateNestedAttribute() { let params = { TableName: tableName, Key: { userId: \u0026#39;johnDoe\u0026#39; }, UpdateExpression: `set albums.album1.images.#img.size = :newImage`, ConditionExpression: `attribute_not_exists(albums.album1.images.#img.size)`, // only creates if size attribute doestnt exists  ExpressionAttributeNames: { \u0026#39;#img\u0026#39;: \u0026#39;img-1\u0026#39; }, ExpressionAttributeValues: { \u0026#39;:newImage\u0026#39;: 2048 } } try { await ddb.update(params).promise() } catch (error) { console.error(error) } }  NOTE: If an attribute name begins with a number or contains a space, a special character, or a reserved word, then you must use an expression attribute name to replace that attribute\u0026rsquo;s name in the expression. In the above example, img-2 attribute has - in its name. So if we set the update expression to ``et albums.album1.images.image-2 = :newImage``it will throw an error.\n APPEND TO A NESTED OBJECT Here we will add a new image to album1\nasync function appendToAnObject () { let newImage = { \u0026#39;filename\u0026#39;: \u0026#39;johndoe/album1/food-826349.jpg\u0026#39;, \u0026#39;s3Url\u0026#39;: \u0026#39;s3://photo-bucket/johndoe/album1/food-826349.jpg\u0026#39;, \u0026#39;tags\u0026#39;: [\u0026#39;burger\u0026#39;, \u0026#39;food\u0026#39;] } let params = { TableName: tableName, Key: { userId: \u0026#39;johnDoe\u0026#39; }, UpdateExpression: `set albums.album1.images.#image = :newImage`, ExpressionAttributeNames: { \u0026#39;#image\u0026#39;: \u0026#39;img-2\u0026#39; }, ExpressionAttributeValues: { \u0026#39;:newImage\u0026#39;: newImage } } try { await ddb.update(params).promise() } catch (error) { console.error(error) } } APPEND TO A LIST Here we will add a couple of tags to one of the image. Tags are stored as an array\nasync function appendToList() { let params = { TableName: tableName, Key: { userId: \u0026#39;johnDoe\u0026#39; }, UpdateExpression: \u0026#39;SET albums.album1.images.#image1.tags = list_append(albums.album1.images.#image1.tags, :newTags)\u0026#39;, ExpressionAttributeNames: { \u0026#39;#image1\u0026#39;: \u0026#39;img-1\u0026#39; }, ExpressionAttributeValues: { \u0026#39;:newTags\u0026#39;: [\u0026#39;burger\u0026#39;, \u0026#39;pizza\u0026#39;] } } try { await ddb.update(params).promise() } catch (error) { console.error(error) } } ","permalink":"https://imewish.github.io/posts/dynamodb-cheatsheet-for-nodejs-javascript/","summary":"Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. DynamoDB lets you offload the administrative burdens of operating and scaling a distributed database so that you don\u0026rsquo;t have to worry about hardware provisioning, setup, and configuration, replication, software patching, or cluster scaling. DynamoDB also offers encryption at rest, which eliminates the operational burden and complexity involved in protecting sensitive data.\nThis cheat sheet will cover the most commonly used scenarios of data operations in DynamoDB with AWS DynamoDB Document client for JavaScript/Nodejs.","title":"DynamoDB CheatSheet For NodeJS/JavaScript"},{"content":"Load testing is an important part when you are designing any type of application, whether it is traditional EC2 based or container-based or a complete serverless application.\nWhy is Load Testing important? Load testing will help us to find the following\n- How fast is the system\n- How much load can the system handle\n- Under what conditions will the system fail\n- Determine our application’s capabilities by measuring its response time, throughput, CPU utilization, latency, etc. during average and heavy user load. This will eventually help in determining the infrastructure needs as the system scales upward.\n- It gives us an opportunity to find strange behavior or surprises when we subject an application to an insane amount of load (stress testing). Strange behaviors include request timeouts, IO Exceptions, memory leaks, or any security issues.\nChoosing a Load testing tool or framework There are many great load testing frameworks available. Some of the leading tools are,\n- Jmeter\n- Locust\n- Artillery.io\nEach of the above tools provides common and some additional features and different methods of load testing. But the only problem with these tools is the throughput it can generate towards your application is limited to the host systems' memory and CPU capacity. If you want to want to test high and quick traffic ramp-up scenarios it\u0026rsquo;s not possible to do it from your laptop or PC. You can either have a high-end PC or you can run it on a Cloud Virtual Machine, it can be expensive, plus some of the above tools come with a GUI, which cannot be accessed via VM\u0026rsquo;s.\nSo how can we do load tests at scale without having a high-end testing infrastructure?\nLoad Testing Serverless Applications with Serverless Artillery Serverless artillery is a combination of serverless framework and artillery.io\nCombine serverless with artillery and you get serverless-artillery for an instant, cheap, and easy performance testing at scale\nServerless-artillery makes it easy to test your services for performance and functionality quickly, easily, and without having to maintain any servers or testing infrastructure.\nUse serverless-artillery if 1. You want to know if your services (either internal or public) can handle different amounts of traffic load (i.e. performance or load testing).\n2. You want to test if your services behave as you expect after you deploy new changes (i.e. acceptance testing).\n3. You want to constantly monitor your services overtime to make sure the latency of your services is under control (i.e. monitoring mode).\nHow It Works - Serverless-artillery would be installed and run on your local machine. From the command line run slsart --help to see various serverless-artillery commands\n- It takes your JSON or YAML load script `script.yml` that specifies,\n- test target/URL/endpoint/service - load progression - and the scenarios that are important for your service to test.  Let\u0026rsquo;s See It in Action *Load Testing A Sample Application*\nIn this example, we will load test a single endpoint(GET) serverless API built with AWS API Gateway, Lambda, and DynamoDB\n*Installing Serverless Artillery on local machine*\n*Prerequisite*\n- NodeJS v8 +\n- Serverless Framework CLI\nnpm install -g serverless  Installing serverless-artillery\nnpm install -g serverless-artillery  To check that the installation succeeded, run:\nslsart --version  We can also install it on a [docker container](https://github.com/Nordstrom/serverless-artillery#installing-in-docker)\n*Setting up the Load Test Configuration*\nmkdir load-test cd load-test slsart script // this will create script.yml config: target: \u0026quot;https://xxxxxxx.execute-api.us-east-1.amazonaws.com\u0026quot; phases: - duration: 300 arrivalRate: 500 rampTo: 10000 scenarios: - flow: - get: url: \u0026quot;/dev/get?id=john\u0026quot;  Understanding `script.yml`\nconfig:\nThe config section defines the target (the hostname or IP address of the system under test),the load progression, and protocol-specific settings such as HTTP response timeouts or [Socket.io](http://socket.io/) transport options\ntarget:\nthe URI of the application under test. For an HTTP application, it\u0026rsquo;s the base URL for all requests\nphases:\nspecify the duration of the test and the frequency of requests\nscenarios:\nThe scenarios section contains definitions for one or more scenarios for the virtual users that Artillery will create.\nflow:\na \u0026ldquo;flow\u0026rdquo; is an array of operations that a virtual user performs, e.g. GET and POST requests for an HTTP-based application\n*Deploy to AWS*\nslsart deploy --stage \u0026lt;your-unique-stage-name\u0026gt;  Start the load Test\nslsart invoke --stage \u0026lt;your-unique-stage-name\u0026gt;  The above \u0026ldquo;script.yml\u0026rdquo; will try to generate 500 user request/second towards the API Gateway Endpoint and it will try to ramp up the requests to 10000/RPS in a period of 5 minutes\nAnd the result of the test will look like this in a cloud watch dashboard.\nAs we can see in the above graph, there are a lot of requests that were throttled by lambda. That is because of lambda\u0026rsquo;s concurrency limit of 1000.\nHow Load Testing Helps Serverless Applications One of the important insights we can get from load testing serverless applications is, It helps to find out the default soft limits or hidden limits of serverless tools. By knowing this we will be able to architecture our application to handle high traffic without throttling the request and hitting the AWS limits.\nIt also helps to find out the following things,\n- Lambda Insights\n- To find concurrency limits - To find out the timeouts - To find out Memory Exceptions - To find out Cold starts (You can warm up or add provisioned concurrency to those functions)  - API Gateway\n- To understand the request throttling limits, increase or decrease them according to application needs  - DynamoDB\n- To get the read write usage metrics and do capacity planning for handling different level of traffic ","permalink":"https://imewish.github.io/posts/load-testing-serverless-sls-artillery/","summary":"Load testing is an important part when you are designing any type of application, whether it is traditional EC2 based or container-based or a complete serverless application.\nWhy is Load Testing important? Load testing will help us to find the following\n- How fast is the system\n- How much load can the system handle\n- Under what conditions will the system fail\n- Determine our application’s capabilities by measuring its response time, throughput, CPU utilization, latency, etc.","title":"Load Testing Serverless Applications With Serverless Artillery"},{"content":"Hosting a static website with S3 is awesome! It is Faster, Cheaper, Zero maintenance.\nIn this article, we will see how to do URL redirects on a website hosted with AWS S3 and Cloudfront.\nThere was a scenario which I was faced once in my company, One of our websites had deleted some old content and replaced it with new content and URL. And when people who google search for that particular content they get the old URL which doest exists.\nTo fix this issue the approach we had was to do add a temporary redirect for that old URL to the new one until it gets updated at google search.\nThe Fix\nAWS S3 Static hosting provides an option to add redirection rules to the website hosted in a particular bucket. https://docs.aws.amazon.com/AmazonS3/latest/dev/how-to-page-redirect.html\nIn this particular case, the URL\u0026rsquo;s we are going to use will be these,\n_https://example.com/content/old-content_\nand we will be redirecting this to\n_https://example.com/content/new/content_\nTo add the rules,\n Click on your bucket Go to properties and click on static website hosting Under the redirection rules filed, put the following code  Redirect Rule,\n\u0026lt;RoutingRules\u0026gt; \u0026lt;RoutingRule\u0026gt; \u0026lt;Condition\u0026gt; \u0026lt;KeyPrefixEquals\u0026gt;content/old-content/\u0026lt;/KeyPrefixEquals\u0026gt; \u0026lt;/Condition\u0026gt; \u0026lt;Redirect\u0026gt; \u0026lt;HostName\u0026gt;example.com\u0026lt;/HostName\u0026gt; \u0026lt;ReplaceKeyPrefixWith\u0026gt;content/new/content\u0026lt;/ReplaceKeyPrefixWith\u0026gt; \u0026lt;/Redirect\u0026gt; \u0026lt;/RoutingRule\u0026gt; \u0026lt;/RoutingRules\u0026gt;  Please note, The HostName(Line 7) part is important if your S3 website is configured with Cloudfront. Else during redirect, the domain name will be replaced with the S3 website endpoint.\nThat\u0026rsquo;s it. Now any requests coming to the old URL will be automatically redirected to the new one\n","permalink":"https://imewish.github.io/posts/2019-12-15-url-redirects-with-aws-s3-and-cloudfront/","summary":"Hosting a static website with S3 is awesome! It is Faster, Cheaper, Zero maintenance.\nIn this article, we will see how to do URL redirects on a website hosted with AWS S3 and Cloudfront.\nThere was a scenario which I was faced once in my company, One of our websites had deleted some old content and replaced it with new content and URL. And when people who google search for that particular content they get the old URL which doest exists.","title":"URL redirects with AWS S3 and Cloudfront"},{"content":"In this guide we will set up a very simple REST API endpoint with the serverless framework, AWS Lambda, and API Gateway and deploy it to AWS Lambda with Github, AWS Codepipeline, Codebuild\n1. Install the Serverless Framework npm install serverless -g 2. Create a project serverless create --template aws-nodejs --path serverless-nodejs-api This will create two files handler.js and serveless.yml\n'use strict'; module.exports.api = async event =\u0026gt; { return { statusCode: 200, body: JSON.stringify( { message: 'Go Serverless v1.0! Your function executed successfully!' }, null, 2 ), }; }; Update your serverless.yml to add an API Gateway endpoint.\nservice: serverless-nodejs-api provider: name: aws runtime: nodejs10.x stage: dev functions: getMsg: handler: handler.api events: - http: GET / Now we have our serverless API code ready.\nYou can deploy this to AWS manually by running sls deploy --stage dev\nThis will deploy the lambda function and create an API gateway endpoint for the function.\nOnce deployed, the output will print the newly created API gateway endpoint. test the function by calling the API endpoint. Something like this,\nService Information service: serverless-nodejs-api stage: dev region: us-east-1 stack: serverless-nodejs-api-dev resources: 9 api keys: None endpoints: GET - https://xxxxx.execute-api.us-east-1.amazonaws.com/dev functions: api: serverless-nodejs-api-dev-getMsg layers: None test the function by calling the API endpoint.\ncurl https://xxxxx.execute-api.us-east-1.amazonaws.com/dev { \u0026quot;message\u0026quot;: \u0026quot;Go Serverless v1.0! Your function executed successfully!\u0026quot; } Now let\u0026rsquo;s automate the deployment process with Github, AWS Codepipeline\nLet\u0026rsquo;s consider this code as production-ready and push the code to the GitHub repo master branch.\nPS: We can create multiple pipelines per brach for eg: Master -\u0026gt; Prod, Development -\u0026gt; Staging/Dev Environment\n3. Setup Codepipeline 3.1 Set Pipeline name and Create IAM Role  3.2 Add source stage In this stage, Connect to your Github account and choose your repo and branch Set the detection method\n3.3 Add build stage In this step, we have to create a Codebuild project, where we configure our build and deploy environment and commands.\nClick on the Create Project button, it will take you to the Codebuild setup page.\nSet the project name here\nChoose your runtime and image for the build environment\nChoose an IAM role for the project - This part is important\nThis role must have enough permissions for the serverless framework to deploy the function and its resources to AWS as follows,\n Create an S3 bucket for your function deployments Upload your function zip files to that S3 bucket Submit a CloudFormation template Create the log groups for your Lambda functions Create a REST API in API Gateway  You can use the below awesome NPM modules to create a narrow IAM policy template that will cover many Serverless use cases.\nnpm install -g yo generator-serverless-policy\nthen on your serverless app directory\n$ yo serverless-policy ? Your Serverless service name test-service ? You can specify a specific stage, if you like: dev ? You can specify a specific region, if you like: us-west-1 ? Does your service rely on DynamoDB? Yes ? Is your service going to be using S3 buckets? Yes app name test-service app stage dev app region us-west-1 Writing to test-service-dev-us-west-1-policy.json After you finish creating the codebuild project go to its IAM role and append the policy with the rules created by the above template.\nYou can find the IAM policy we used for this guide here, https://github.com/imewish/serverless-nodejs-api/blob/master/codebuild-IAM-policy.json\nDefine Build Spec.\nYou can find it here. https://github.com/imewish/serverless-nodejs-api/blob/master/buildspec.yml\n Here we will define the commands to set up the serverless framework and deploy commands to AWS.\nOn install phase\n  Set nodejs 10 as runtime\n  Install serverless framework On Build Phase\n  Install npm packages\n  Deploy to lambda with sls deploy --stage dev/prod\n   NB: You can also run your tests here if you have test cases written for your lambda functions.\nEnable Cloudwatch logs so that we can tail our build process logs.\nThen click on Continue to Codepipeline this will take us back to Codepipeline Setup.\n4. Deploy Stage This stage is optional.\nSince the serverless framework already put the deployment artifacts to an S3 bucket we can skip this part. But if you want to store it to a different bucket you can set up like this.\nClick Next and then review all the setup then Create the pipeline.\nThat\u0026rsquo;s it!. Now you can test this by going to the newly created pipeline and click on Release Change\n","permalink":"https://imewish.github.io/posts/2019-11-23-automating-deployment-of-lambda-functions-using-serverless-framework-aws-codepipeline/","summary":"In this guide we will set up a very simple REST API endpoint with the serverless framework, AWS Lambda, and API Gateway and deploy it to AWS Lambda with Github, AWS Codepipeline, Codebuild\n1. Install the Serverless Framework npm install serverless -g 2. Create a project serverless create --template aws-nodejs --path serverless-nodejs-api This will create two files handler.js and serveless.yml\n'use strict'; module.exports.api = async event =\u0026gt; { return { statusCode: 200, body: JSON.","title":"Automating Deployment Of Lambda Functions Using Serverless Framework, AWS CodePipeline"},{"content":"An AWS and Serverless enthusiast, Experienced Serverless Developer/DevOps Engineer with a demonstrated history of working in the OTT and E-Commerce Industries.\n","permalink":"https://imewish.github.io/about-hugo/","summary":"An AWS and Serverless enthusiast, Experienced Serverless Developer/DevOps Engineer with a demonstrated history of working in the OTT and E-Commerce Industries.","title":"About Me"}]